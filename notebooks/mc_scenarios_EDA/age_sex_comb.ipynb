{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import statistics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_dir = '../../data/processed/scenarios/'\n",
    "scenario_dir = 'scenarios_1_1_pub_trans_comfort_dist-up_0_0_pub_trans_punctuality_dist-up_0_0_household_cars_dist-down_0_0/'\n",
    "\n",
    "scenario_path = os.path.join(scenarios_dir, scenario_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Step  AgentID  agent_id  home_region  age_sex  pub_trans_comfort  \\\n",
       "0     0        0         0          184   61-x_K                3.0   \n",
       "1     0        1         1          195  45-60_K                2.0   \n",
       "2     0        2         2           68      0-5                NaN   \n",
       "3     0        3         3          160  16-19_M                3.0   \n",
       "4     0        4         4          261  45-65_M                3.0   \n",
       "\n",
       "   pub_trans_punctuality  bicycle_infrastr_comfort  pedestrian_inconvenience  \\\n",
       "0                    4.0                       2.0                       0.0   \n",
       "1                    2.0                       2.0                       3.0   \n",
       "2                    NaN                       NaN                       NaN   \n",
       "3                    2.0                       3.0                       1.0   \n",
       "4                    2.0                       2.0                       0.0   \n",
       "\n",
       "   household_persons  household_cars  household_bicycles  travels_num  \n",
       "0                3.0             0.0                 2.0            0  \n",
       "1                3.0             0.0                 3.0            2  \n",
       "2                NaN             NaN                 NaN            0  \n",
       "3                3.0             1.0                 3.0            2  \n",
       "4                2.0             1.0                 2.0            0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Step</th>\n      <th>AgentID</th>\n      <th>agent_id</th>\n      <th>home_region</th>\n      <th>age_sex</th>\n      <th>pub_trans_comfort</th>\n      <th>pub_trans_punctuality</th>\n      <th>bicycle_infrastr_comfort</th>\n      <th>pedestrian_inconvenience</th>\n      <th>household_persons</th>\n      <th>household_cars</th>\n      <th>household_bicycles</th>\n      <th>travels_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>184</td>\n      <td>61-x_K</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>195</td>\n      <td>45-60_K</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>68</td>\n      <td>0-5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>160</td>\n      <td>16-19_M</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>261</td>\n      <td>45-65_M</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 205
    }
   ],
   "source": [
    "agents_examp = pd.read_csv(os.path.join(scenario_path, 'agents_results_1.csv'))\n",
    "\n",
    "agents_examp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   agent_id  start_region start_place_type  dest_region dest_place_type  \\\n",
       "0         1           195              dom          195            inne   \n",
       "1         1           195             inne          195             dom   \n",
       "2         3           160              dom          135          szkola   \n",
       "3         3           135           szkola          160             dom   \n",
       "4         5           205              dom          139            inne   \n",
       "\n",
       "   travel_start_time  transport_mode  is_driver  \n",
       "0                787               2        NaN  \n",
       "1                797               2        NaN  \n",
       "2                468               1        NaN  \n",
       "3                478               1        NaN  \n",
       "4               1099               0        0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>agent_id</th>\n      <th>start_region</th>\n      <th>start_place_type</th>\n      <th>dest_region</th>\n      <th>dest_place_type</th>\n      <th>travel_start_time</th>\n      <th>transport_mode</th>\n      <th>is_driver</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>195</td>\n      <td>dom</td>\n      <td>195</td>\n      <td>inne</td>\n      <td>787</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>195</td>\n      <td>inne</td>\n      <td>195</td>\n      <td>dom</td>\n      <td>797</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>160</td>\n      <td>dom</td>\n      <td>135</td>\n      <td>szkola</td>\n      <td>468</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>135</td>\n      <td>szkola</td>\n      <td>160</td>\n      <td>dom</td>\n      <td>478</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>205</td>\n      <td>dom</td>\n      <td>139</td>\n      <td>inne</td>\n      <td>1099</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 206
    }
   ],
   "source": [
    "travels_examp = pd.read_csv(os.path.join(scenario_path, 'travels_results_1.csv'), index_col=0)\n",
    "\n",
    "travels_examp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(944739, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "source": [
    "travels_examp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     ‘grupa_wiek_plec’: {\n",
    "# \t\t‘modal_split’: {\n",
    "# \t\t\t‘komunikacja’: {\n",
    "#                 średnia: średnia liczba przejazdów komunikacją,\n",
    "#                 ‘std’: wartość\n",
    "#             }\n",
    "# \t\t\t‘auta_kierowca’: jw\n",
    "# \t\t\t‘auta_nie_kierowca’: jw\n",
    "# \t\t\titd.\n",
    "# \t\t},\n",
    "# \t\t‘rozklad na cele podrozy’: {\n",
    "# \t\t\t‘dom’: {\n",
    "#                 ‘średnia’: średnia liczba podróży do domu\n",
    "#                 ‘std’: std:\n",
    "#             }\n",
    "# \t\t\titd.\n",
    "# \t\t},\n",
    "# \t\t‘liczba podróży’: {\n",
    "#             średnia\n",
    "#         },\n",
    "#         pub_trans_comfort: {\n",
    "#             średnia ocena\n",
    "#         },\n",
    "#         pub_trans_punctuality: {\n",
    "#             średnia ocena\n",
    "#         },\n",
    "#         bicycle_infrastr_comfort: {\n",
    "#             średnia ocena\n",
    "#         },\n",
    "#         pedestrian_inconvenience: {\n",
    "#             średnia\n",
    "#         },\n",
    "#         household_persons: {\n",
    "#             średnia\n",
    "#         },\n",
    "#         household_cars: {\n",
    "#             średnia\n",
    "#         },\n",
    "#         household_bicycles: {\n",
    "#             średnia\n",
    "#         }\n",
    "# \t}\n",
    "# }"
   ]
  },
  {
   "source": [
    "## Automa"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_dir = '../../data/processed/scenarios/'\n",
    "\n",
    "# 0 0 0\n",
    "scenario_dir = 'scenarios_1_1_pub_trans_comfort_dist-up_0_0_pub_trans_punctuality_dist-up_0_0_household_cars_dist-down_0_0/'\n",
    "out_file = 'asc_scenario_0_0_0.json'\n",
    "\n",
    "# 0 0 3\n",
    "# scenario_dir = 'scenarios_2_1_pub_trans_comfort_dist-up_0_0_pub_trans_punctuality_dist-up_0_0_household_cars_dist-down_0_3/'\n",
    "# out_file = 'asc_scenario_0_0_3.json'\n",
    "\n",
    "# 3 3 0\n",
    "# scenario_dir = 'scenarios_10_1_pub_trans_comfort_dist-up_0_3_pub_trans_punctuality_dist-up_0_3_household_cars_dist-down_0_0/'\n",
    "# out_file = 'asc_scenario_3_3_0.json'\n",
    "\n",
    "# 3 3 3\n",
    "# scenario_dir = 'scenarios_11_1_pub_trans_comfort_dist-up_0_3_pub_trans_punctuality_dist-up_0_3_household_cars_dist-down_0_3/'\n",
    "# out_file = 'asc_scenario_3_3_3.json'\n",
    "\n",
    "# 0 0 15\n",
    "# scenario_dir = 'scenarios_9_1_pub_trans_comfort_dist-up_0_0_pub_trans_punctuality_dist-up_0_0_household_cars_dist-down_0_15/'\n",
    "# out_file = 'asc_scenario_0_0_15.json'\n",
    "\n",
    "# 15 15 0\n",
    "# scenario_dir = 'scenarios_5_1_pub_trans_comfort_dist-up_0_15_pub_trans_punctuality_dist-up_0_15_household_cars_dist-down_0_0/'\n",
    "# out_file = 'asc_scenario_15_15_0.json'\n",
    "\n",
    "# 15 15 15\n",
    "# scenario_dir = 'scenarios_6_1_pub_trans_comfort_dist-up_0_15_pub_trans_punctuality_dist-up_0_15_household_cars_dist-down_0_15/'\n",
    "# out_file = 'asc_scenario_15_15_15.json'\n",
    "\n",
    "scenario_path = os.path.join(scenarios_dir, scenario_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "execution_count": 195
    }
   ],
   "source": [
    "simulations_files = [f for f in os.listdir(scenario_path) if f.startswith(('agents_results_', 'travels_results_'))]\n",
    "num_simulations = int(len(simulations_files) / 2)\n",
    "\n",
    "num_simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_age_sex = [\n",
    "    '6-15_K',\n",
    "    '6-15_M',\n",
    "    '16-19_K',\n",
    "    '16-19_M',\n",
    "    '20-24_K',\n",
    "    '20-24_M',\n",
    "    '25-44_K',\n",
    "    '25-44_M',\n",
    "    '45-60_K',\n",
    "    '45-65_M',\n",
    "    '61-x_K',\n",
    "    '66-x_M'\n",
    "]\n",
    "\n",
    "unique_transport_mode = [\n",
    "    'car_driver',\n",
    "    'car_passenger',\n",
    "    'public',\n",
    "    'pedestrian',\n",
    "    'bicycle'\n",
    "]\n",
    "\n",
    "unique_dest_place_type = [\n",
    "    'dom', \n",
    "    'inne', \n",
    "    'praca', \n",
    "    'szkola', \n",
    "    'uczelnia'\n",
    "]\n",
    "\n",
    "other_params = [\n",
    "    'travels_num',\n",
    "    'pub_trans_comfort',\n",
    "    'pub_trans_punctuality',\n",
    "    'bicycle_infrastr_comfort',\n",
    "    'pedestrian_inconvenience',\n",
    "    'household_persons',\n",
    "    'household_cars',\n",
    "    'household_bicycles'\n",
    "]\n",
    "\n",
    "statistics = [\n",
    "    'mean', \n",
    "    'std',\n",
    "    'median',\n",
    "    'list'\n",
    "]\n",
    "\n",
    "\n",
    "json_dict = {}\n",
    "\n",
    "for age_sex_comb in unique_age_sex:\n",
    "    json_dict[age_sex_comb] = {}\n",
    "\n",
    "    json_dict[age_sex_comb]['modal_split'] = {}\n",
    "    for tm in unique_transport_mode:\n",
    "        json_dict[age_sex_comb]['modal_split'][tm] = {}\n",
    "        for stat in statistics:\n",
    "            json_dict[age_sex_comb]['modal_split'][tm][stat] = []\n",
    "    \n",
    "    json_dict[age_sex_comb]['dest_place_type'] = {}\n",
    "    for dpt in unique_dest_place_type:\n",
    "        json_dict[age_sex_comb]['dest_place_type'][dpt] = {}\n",
    "        for stat in statistics:\n",
    "            json_dict[age_sex_comb]['dest_place_type'][dpt][stat] = []\n",
    "    \n",
    "    for param in other_params:\n",
    "        json_dict[age_sex_comb][param] = {}\n",
    "        for stat in statistics:\n",
    "            json_dict[age_sex_comb][param][stat] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transport_mode_count(df_travels, age_sex_comb, tm):\n",
    "    if tm.startswith('car_'):\n",
    "        if tm == 'car_driver':\n",
    "            transport_mode = 0\n",
    "            is_driver = 1.0\n",
    "        else:\n",
    "            transport_mode = 0\n",
    "            is_driver = 0.0\n",
    "\n",
    "        count = df_travels[\n",
    "            (df_travels['age_sex'] == age_sex_comb) &\n",
    "            (df_travels['transport_mode'] == transport_mode) &\n",
    "            (df_travels['is_driver'] == is_driver)\n",
    "        ].shape[0]\n",
    "    else:\n",
    "        if tm == 'public':\n",
    "            transport_mode = 1\n",
    "        elif tm == 'pedestrian':\n",
    "            transport_mode = 2\n",
    "        elif tm == 'bicycle':\n",
    "            transport_mode = 3\n",
    "        else:\n",
    "            transport_mode = -1\n",
    "        \n",
    "        count = df_travels[\n",
    "            (df_travels['age_sex'] == age_sex_comb) &\n",
    "            (df_travels['transport_mode'] == transport_mode)\n",
    "        ].shape[0]\n",
    "    \n",
    "    return count\n",
    "\n",
    "\n",
    "def dest_place_type_count(df_travels, age_sex_comb, dpt):\n",
    "    count = df_travels[\n",
    "        (df_travels['age_sex'] == age_sex_comb) &\n",
    "        (df_travels['dest_place_type'] == dpt)\n",
    "    ].shape[0]\n",
    "    \n",
    "    return count\n",
    "\n",
    "\n",
    "def get_travels_num(df_travels, age_sex_comb):\n",
    "    count = df_travels[\n",
    "        df_travels['age_sex'] == age_sex_comb\n",
    "    ].shape[0]\n",
    "    \n",
    "    return count\n",
    "\n",
    "\n",
    "def get_avg_param(df_agents, age_sex_comb, param):\n",
    "    df_agents_filtred = df_agents[\n",
    "        df_travels['age_sex'] == age_sex_comb\n",
    "    ]\n",
    "    avg = df_agents_filtred[param].mean()\n",
    "\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:22<37:00, 22.43s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:45<36:51, 22.56s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [01:06<35:40, 22.07s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [01:26<34:36, 21.63s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [01:47<33:38, 21.25s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [02:09<33:52, 21.62s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [02:30<32:54, 21.23s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [02:50<31:59, 20.87s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [03:10<31:19, 20.65s/it]\u001b[A\n",
      " 10%|█         | 10/100 [03:30<30:47, 20.52s/it]\u001b[A\n",
      " 11%|█         | 11/100 [03:52<31:13, 21.05s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [04:13<30:53, 21.06s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [04:31<29:01, 20.02s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [04:49<27:48, 19.40s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [05:07<26:50, 18.95s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [05:25<26:27, 18.90s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [05:48<27:46, 20.08s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [06:11<28:18, 20.72s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [06:32<28:08, 20.84s/it]\u001b[A\n",
      " 20%|██        | 20/100 [06:53<28:02, 21.03s/it]\u001b[A\n",
      " 21%|██        | 21/100 [07:18<29:00, 22.03s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [07:37<27:49, 21.41s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [07:59<27:20, 21.30s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [08:21<27:27, 21.68s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [08:44<27:36, 22.09s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [09:09<28:11, 22.86s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [09:32<28:01, 23.04s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [09:56<27:46, 23.14s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [10:17<26:49, 22.67s/it]\u001b[A\n",
      " 30%|███       | 30/100 [10:39<26:00, 22.29s/it]\u001b[A\n",
      " 31%|███       | 31/100 [11:02<26:05, 22.69s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [11:26<26:00, 22.95s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [11:45<24:31, 21.97s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [12:03<22:43, 20.65s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [12:22<21:45, 20.09s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [12:41<21:06, 19.79s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [12:59<20:21, 19.39s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [13:19<19:58, 19.34s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [13:39<20:05, 19.77s/it]\u001b[A\n",
      " 40%|████      | 40/100 [13:59<19:38, 19.65s/it]\u001b[A\n",
      " 41%|████      | 41/100 [14:17<19:00, 19.33s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [14:38<19:04, 19.74s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [14:58<18:47, 19.78s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [15:18<18:28, 19.80s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [15:39<18:25, 20.10s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [16:00<18:22, 20.41s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [16:18<17:33, 19.89s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [16:37<16:54, 19.51s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [16:56<16:22, 19.27s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [17:14<15:53, 19.07s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [17:33<15:27, 18.92s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [17:52<15:04, 18.85s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [18:10<14:44, 18.82s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [18:29<14:22, 18.76s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [18:48<14:11, 18.92s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [19:11<14:45, 20.12s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [19:32<14:39, 20.45s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [19:54<14:33, 20.80s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [20:17<14:45, 21.59s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [20:38<14:16, 21.41s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [21:01<14:10, 21.82s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [21:25<14:08, 22.32s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [21:47<13:42, 22.22s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [22:09<13:22, 22.29s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [22:31<12:53, 22.11s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [22:51<12:13, 21.56s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [23:12<11:46, 21.41s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [23:35<11:37, 21.81s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [23:59<11:36, 22.46s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [24:25<11:42, 23.43s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [24:49<11:28, 23.73s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [25:12<10:56, 23.44s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [25:37<10:44, 23.89s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [26:00<10:16, 23.73s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [26:23<09:50, 23.60s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [26:47<09:25, 23.56s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [27:08<08:47, 22.95s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [27:30<08:14, 22.49s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [27:53<07:55, 22.64s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [28:15<07:33, 22.66s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [28:36<06:56, 21.94s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [28:58<06:36, 22.00s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [29:22<06:24, 22.62s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [29:44<06:01, 22.61s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [30:08<05:42, 22.85s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [30:28<05:09, 22.11s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [30:48<04:37, 21.37s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [31:08<04:10, 20.88s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [31:27<03:45, 20.51s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [31:47<03:23, 20.32s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [32:10<03:09, 21.09s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [32:32<02:49, 21.21s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [32:55<02:32, 21.76s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [33:14<02:07, 21.21s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [33:35<01:44, 20.95s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [34:04<01:34, 23.52s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [34:28<01:10, 23.64s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [34:50<00:46, 23.10s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [35:11<00:22, 22.45s/it]\u001b[A\n",
      "100%|██████████| 100/100 [35:32<00:00, 21.33s/it]\n"
     ]
    }
   ],
   "source": [
    "simulations_files = [f for f in os.listdir(scenario_path) if f.startswith(('agents_results_', 'travels_results_'))]\n",
    "num_simulations = int(len(simulations_files) / 2)\n",
    "\n",
    "# for simulation in tqdm(range(1, 3)):\n",
    "for simulation in tqdm(range(1, num_simulations+1)):\n",
    "    agents_file = 'agents_results_' + str(simulation) + '.csv'\n",
    "    travels_file = 'travels_results_' + str(simulation) + '.csv'\n",
    "    df_agents = pd.read_csv(os.path.join(scenario_path, agents_file))\n",
    "    df_travels = pd.read_csv(os.path.join(scenario_path, travels_file), index_col=0)\n",
    "\n",
    "    df_travels = pd.merge(df_travels, df_agents[['agent_id','age_sex']], on='agent_id', how='left') # left - means agents who have not attempted to travel do not exist in this df\n",
    "\n",
    "    for age_sex_comb in unique_age_sex:\n",
    "        for tm in unique_transport_mode:\n",
    "            count = transport_mode_count(df_travels, age_sex_comb, tm)\n",
    "            for stat in statistics:\n",
    "                json_dict[age_sex_comb]['modal_split'][tm][stat].append(count)\n",
    "        \n",
    "        for dpt in unique_dest_place_type:\n",
    "            count = dest_place_type_count(df_travels, age_sex_comb, dpt)\n",
    "            for stat in statistics:\n",
    "                json_dict[age_sex_comb]['dest_place_type'][dpt][stat].append(count)\n",
    "        \n",
    "        for param in other_params:\n",
    "            if param == 'travels_num':\n",
    "                count = get_travels_num(df_travels, age_sex_comb)\n",
    "                for stat in statistics:\n",
    "                    json_dict[age_sex_comb][param][stat].append(count)\n",
    "            else:\n",
    "                avg = get_avg_param(df_agents, age_sex_comb, param)\n",
    "                for stat in statistics:\n",
    "                    json_dict[age_sex_comb][param][stat].append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 12/12 [00:00<00:00, 78.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "for age_sex_comb in tqdm(unique_age_sex):\n",
    "    for tm in unique_transport_mode:\n",
    "        json_dict[age_sex_comb]['modal_split'][tm]['mean'] = statistics.mean(json_dict[age_sex_comb]['modal_split'][tm]['mean'])\n",
    "        json_dict[age_sex_comb]['modal_split'][tm]['std'] = statistics.stdev(json_dict[age_sex_comb]['modal_split'][tm]['std'])\n",
    "        json_dict[age_sex_comb]['modal_split'][tm]['median'] = statistics.median(json_dict[age_sex_comb]['modal_split'][tm]['median'])\n",
    "    \n",
    "    for dpt in unique_dest_place_type:\n",
    "        json_dict[age_sex_comb]['dest_place_type'][dpt]['mean'] = statistics.mean(json_dict[age_sex_comb]['dest_place_type'][dpt]['mean'])\n",
    "        json_dict[age_sex_comb]['dest_place_type'][dpt]['std'] = statistics.stdev(json_dict[age_sex_comb]['dest_place_type'][dpt]['std'])\n",
    "        json_dict[age_sex_comb]['dest_place_type'][dpt]['median'] = statistics.median(json_dict[age_sex_comb]['dest_place_type'][dpt]['median'])\n",
    "    \n",
    "    for param in other_params:\n",
    "        json_dict[age_sex_comb][param]['mean'] = statistics.mean(json_dict[age_sex_comb][param]['mean'])\n",
    "        json_dict[age_sex_comb][param]['std'] = statistics.stdev(json_dict[age_sex_comb][param]['std'])\n",
    "        json_dict[age_sex_comb][param]['median'] = statistics.median(json_dict[age_sex_comb][param]['median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_dict['6-15_K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '../../data/processed/mc/scenarios'\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(out_dir, out_file)\n",
    "\n",
    "with open(out_path, 'w') as f:\n",
    "    json.dump(json_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}